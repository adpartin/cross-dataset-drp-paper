"""
Step 6: Compute Drug and Cell Overlap Metrics
==============================================

This step computes simple, interpretable dataset similarity metrics based on
drug and cell overlap, and compares directional coverage to cross-dataset
performance (G matrices from Step 2).

PURPOSE:
--------
- Computes overlap metrics for drugs and cells across datasets:
  * overlap_count (|Ei ∩ Ej|)
  * overlap_jaccard (|Ei ∩ Ej| / |Ei ∪ Ej|)  [symmetric similarity]
  * directional_coverage (|Es ∩ Et| / |Et|)  [rows=Source, cols=Target]
- Compares directional coverage to G(s,t) off-diagonals via Spearman correlation,
  overall and within same-assay subset
- Generates heatmaps and scatter plots for visualization

INPUT:
------
- Prediction CSV files from test_preds/ directory (generated by Step 0 or downloaded)
- Files follow pattern: <SRC>_<TRG>_split_<SPLITID>_<MODEL>.csv
- G matrices from outputs/s2_G_matrices/ (generated by Step 2)
- Specifically: {model}_{metric}_G_mean.csv

OUTPUT:
-------
- Creates s6_overlap/ directory with output files
- CSV files: drug_directional_coverage.csv, cell_directional_coverage.csv
- Figures: Heatmaps and scatter plots saved to outputs/s6_overlap/figures/
  * Each figure is saved in both the specified format (default: eps) and PNG:
  * heatmap_directional_drug_coverage.{format} and .png
  * heatmap_directional_cell_coverage.{format} and .png
  * scatter_drug_coverage_vs_G_all_{model}.{format} and .png
  * scatter_drug_coverage_vs_G_by_assay_{model}.{format} and .png
  * scatter_cell_coverage_vs_G_all_{model}.{format} and .png
  * scatter_cell_coverage_vs_G_by_assay_{model}.{format} and .png

Assumptions:
  * Prediction CSVs in preds_dir named:
      <SRC>_<TRG>_split_<SPLITID>_<MODEL>.csv
  * Each file with TARGET=T contains predictions for ALL cell–drug pairs in T,
    except files where SRC==TRG (those typically contain only test splits; avoided).
  * Required columns:
      - 'improve_chem_id' for drug overlap
      - 'improve_sample_id' for cell overlap

USAGE:
------
    python s6_overlap.py [--preds_dir <path>] [--G_dir <path>] [--model <model>] \\
                         [--metric <metric>] [--outdir <path>] [--file_format <format>]
"""

from __future__ import annotations

import argparse
import logging
import re
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import spearmanr

from postprocess_utils import setup_logging
from utils import model_name_mapping

# ----------------------------
# CONFIG (defaults)
# ----------------------------

DATASET_ORDER = ['CCLE', 'CTRPv2', 'GDSCv1', 'GDSCv2', 'gCSI']

DEFAULT_REP_FILES = {
    'CTRPv2': 'CCLE_CTRPv2_split_0_deepcdr.csv',
    'gCSI':   'CCLE_gCSI_split_0_deepcdr.csv',
    'GDSCv1': 'CCLE_GDSCv1_split_0_deepcdr.csv',
    'GDSCv2': 'CCLE_GDSCv2_split_0_deepcdr.csv',
    'CCLE':   'CTRPv2_CCLE_split_0_deepcdr.csv',  # ensure SRC != TRG to cover full CCLE
}

# Required columns
REQUIRED_DRUG_COL = 'improve_chem_id'
REQUIRED_CELL_COL = 'improve_sample_id'

ASSAY_MAP = {
    'CCLE': 'CTG',      # CellTiter-Glo
    'CTRPv2': 'CTG',
    'gCSI': 'CTG',
    'GDSCv1': 'Syto60',
    'GDSCv2': 'CTG',
}

# ----------------------------
# Filename parsing helpers
# ----------------------------

FILENAME_RE = re.compile(
    r'^(?P<src>[^_]+)_(?P<trg>[^_]+)_split_(?P<split>\d+)_(?P<model>[^.]+)\.csv$'
)

def parse_filename(path: Path) -> Optional[dict]:
    m = FILENAME_RE.match(path.name)
    return m.groupdict() if m else None

def choose_representative_file(
    preds_dir: Path,
    target: str,
    default_map: Dict[str, str]) -> Path:
    """
    Choose one CSV whose TARGET == target and ideally SRC != TRG (to ensure full coverage).
    Preference order:
      (1) default_map[target] if it exists
      (2) any '*_<target>_split_0_*' with SRC != TRG
      (3) any '*_<target>_split_*_*' with SRC != TRG
      (4) any '*_<target>_split_*_*' (fallback, may be SRC==TRG if nothing else)
    """
    preferred = preds_dir / default_map.get(target, "")
    if preferred.name and preferred.exists():
        return preferred

    def pick(pattern: str, prefer_src_neq_trg: bool) -> Optional[Path]:
        matches = sorted(preds_dir.glob(pattern))
        if not matches:
            return None
        if prefer_src_neq_trg:
            for p in matches:
                info = parse_filename(p)
                if info and info['src'] != info['trg']:
                    return p
            return None
        return matches[0]

    p = pick(f"*_{target}_split_0_*.csv", prefer_src_neq_trg=True)
    if p:
        return p
    p = pick(f"*_{target}_split_*_*.csv", prefer_src_neq_trg=True)
    if p:
        return p
    p = pick(f"*_{target}_split_*_*.csv", prefer_src_neq_trg=False)
    if p:
        return p

    raise FileNotFoundError(f"No prediction CSV found for target '{target}' in {preds_dir}")

# ----------------------------
# Loading entity sets (DRUG/CELL)
# ----------------------------

def load_unique_ids(csv_path: Path, required_col: str) -> Set[str]:
    """Load unique values from a single column; fail fast if column missing."""
    header = pd.read_csv(csv_path, nrows=0).columns.tolist()
    if required_col not in header:
        raise ValueError(
            f"File {csv_path} missing required column '{required_col}'. "
            f"Columns found: {header}"
        )
    series = pd.read_csv(csv_path, usecols=[required_col])[required_col].astype(str)
    return set(series.unique())

def build_entity_sets(
    preds_dir: Path,
    required_col: str,
    dataset_order: List[str] = DATASET_ORDER,
    default_map: Dict[str, str] = DEFAULT_REP_FILES,
    log_label: str = "entity"
    ) -> Dict[str, Set[str]]:
    """
    Discover TARGET datasets in preds_dir and build {dataset: set(ids)} for the given column.
    Uses one representative TARGET CSV per dataset (SRC != TRG preferred).
    """
    targets_found = set()
    for p in preds_dir.glob("*.csv"):
        info = parse_filename(p)
        if info:
            targets_found.add(info['trg'])
    if not targets_found:
        raise RuntimeError(f"No valid prediction files found in: {preds_dir}")

    targets = [d for d in dataset_order if d in targets_found]

    entity_sets: Dict[str, Set[str]] = {}
    for trg in targets:
        rep = choose_representative_file(preds_dir, trg, default_map)
        ids = load_unique_ids(rep, required_col=required_col)
        entity_sets[trg] = ids
        logging.info(f"[{trg}] using {rep.name} | unique {log_label}s: {len(ids)}")

    return entity_sets

# ----------------------------
# Overlap matrix computations
# ----------------------------

def compute_overlap_matrices(
    entity_sets: Dict[str, Set[str]],
    dataset_order: Optional[List[str]] = None
    ) -> Dict[str, pd.DataFrame]:
    """
    Given per-dataset sets, compute:
      - overlap_count (|Ei ∩ Ej|) [symmetric]
      - overlap_jaccard (|Ei ∩ Ej| / |Ei ∪ Ej|) [symmetric]
      - directional_coverage (|Es ∩ Et| / |Et|) [rows=Source, cols=Target]
    """
    idx = [d for d in (dataset_order or list(entity_sets.keys())) if d in entity_sets]

    count = pd.DataFrame(0, index=idx, columns=idx, dtype=int)
    jacc  = pd.DataFrame(0.0, index=idx, columns=idx, dtype=float)
    covg  = pd.DataFrame(0.0, index=idx, columns=idx, dtype=float)

    for si in idx:
        Ei = entity_sets[si]
        for sj in idx:
            Ej = entity_sets[sj]
            inter = len(Ei & Ej)
            union = len(Ei | Ej) if (Ei or Ej) else 0
            count.loc[si, sj] = inter
            jacc.loc[si, sj]  = (inter / union) if union > 0 else 0.0
            covg.loc[si, sj]  = (inter / len(Ej)) if len(Ej) > 0 else 0.0  # S->T

    return {"overlap_count": count, "overlap_jaccard": jacc, "directional_coverage": covg}

# ----------------------------
# Performance matrix utilities
# ----------------------------

def load_performance_matrix(g_csv: Path) -> pd.DataFrame:
    G = pd.read_csv(g_csv, index_col=0)
    return G.apply(pd.to_numeric, errors='coerce')

def flatten_offdiag(
    A: pd.DataFrame,
    B: pd.DataFrame
    ) -> Tuple[np.ndarray, np.ndarray, List[Tuple[str, str]]]:
    A2, B2 = A.align(B, join='inner', axis=0)
    A2, B2 = A2.align(B2, join='inner', axis=1)
    xs, ys, labels = [], [], []
    for s in A2.index:
        for t in A2.columns:
            if s == t:
                continue
            a = A2.loc[s, t]; b = B2.loc[s, t]
            if pd.notna(a) and pd.notna(b):
                xs.append(float(a)); ys.append(float(b)); labels.append((s, t))
    return np.array(xs), np.array(ys), labels

def filter_same_assay_pairs(labels: List[Tuple[str, str]], assay_map: Dict[str, str]) -> List[bool]:
    mask = []
    for s, t in labels:
        same = (assay_map.get(s) is not None) and (assay_map.get(s) == assay_map.get(t))
        mask.append(bool(same))
    return mask

# ----------------------------
# Plotting (matplotlib only)
# ----------------------------

def plot_heatmap(
    df: pd.DataFrame,
    title: str,
    out_png: Path,
    vmin=None,
    vmax=None,
    cmap='viridis',
    fmt='{:.2f}'
    ) -> bool:
    """Simple annotated heatmap for small matrices (rows=sources, cols=targets)."""
    fig, ax = plt.subplots(figsize=(6.5, 5))
    im = ax.imshow(df.values, aspect='auto', vmin=vmin, vmax=vmax, cmap=cmap)

    ax.set_xticks(range(len(df.columns)))
    ax.set_xticklabels(list(df.columns), rotation=45, ha='right', fontsize=11)
    ax.set_yticks(range(len(df.index)))
    ax.set_yticklabels(list(df.index), fontsize=11)

    ax.set_xlabel("Target Dataset", fontsize=11)
    ax.set_ylabel("Source Dataset", fontsize=11)
    plt.xticks(rotation=0, ha='center')
    ax.set_title(title, fontsize=12)

    # Annotate each cell with a value string; choose text color by normalized intensity
    for i in range(len(df.index)):
        for j in range(len(df.columns)):
            val = df.iat[i, j]
            try:
                text = fmt.format(val)
            except Exception:
                text = str(val)
            ax.text(
                j, i, text,
                ha='center', va='center', fontsize=11,
                color='white' if (im.norm(val) > 0.5) else 'black'
            )

    cbar = plt.colorbar(im, ax=ax)
    # cbar.set_label(title, rotation=270, labelpad=12)

    plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()
    return True


def plot_scatter(
    x: np.ndarray,
    y: np.ndarray,
    labels: List[Tuple[str, str]],
    assay_map: Dict[str, str],
    title: str,
    out_png: Path,
    xlabel: str,
    show_assay_split: bool = False,
    # Optional colors to keep visuals consistent with heatmaps:
    # - use color_all for single-color mode,
    # - use color_same / color_diff for by-assay mode.
    color_all: Optional[str] = None,
    color_same: Optional[str] = None,
    color_diff: Optional[str] = None
    ) -> bool:
    """Scatter x vs y for off-diagonal (S,T) pairs, with optional assay-based coloring."""
    fig, ax = plt.subplots(figsize=(6.5, 5.2))

    if show_assay_split:
        mask_same = np.array(filter_same_assay_pairs(labels, assay_map))
        mask_diff = ~mask_same

        ax.scatter(
            x[mask_same], y[mask_same],
            alpha=0.85, s=46, label='Same assay',
            color=(color_same or 'tab:blue')
        )
        ax.scatter(
            x[mask_diff], y[mask_diff],
            alpha=0.75, s=46, label='Different assay',
            color=(color_diff or '0.55')  # neutral gray by default
        )
        ax.legend(loc='lower right', frameon=True)
    else:
        ax.scatter(
            x, y,
            alpha=0.85, s=46, label='All pairs',
            color=(color_all or 'tab:blue')
        )

    ax.set_xlabel(xlabel)
    ax.set_ylabel("Cross-dataset performance, g(s,t)")
    ax.set_title(title)

    # Correlations (Spearman)
    rho_all, p_all = spearmanr(x, y, nan_policy='omit')
    # txt = f"Spearman ρ (all) = {rho_all:.2f} (p={p_all:.3g})"
    txt = f"Spearman ρ = {rho_all:.2f} (p={p_all:.3g})"

    if show_assay_split:
        mask_same = np.array(filter_same_assay_pairs(labels, assay_map))
        if np.any(mask_same):
            rho_same, p_same = spearmanr(x[mask_same], y[mask_same], nan_policy='omit')
            txt += f"\nSpearman ρ (same assay) = {rho_same:.2f} (p={p_same:.3g})"

    ax.text(
        0.02, 0.98, txt,
        transform=ax.transAxes, ha='left', va='top', fontsize=9,
        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7, edgecolor='none')
    )

    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()
    return True


# ----------------------------
# Main CLI
# ----------------------------

def main():
    start_time = time.time()

    parser = argparse.ArgumentParser(
        description='Step 6: Compute drug and cell overlap metrics vs cross-dataset performance (G).',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--preds_dir',
        type=str,
        default='./test_preds',
        help='Directory containing prediction CSV files (default: ./test_preds)'
    )
    parser.add_argument(
        '--G_dir',
        type=str,
        default='./outputs/s2_G_matrices',
        help='Directory containing G matrices from Step 2 (default: ./outputs/s2_G_matrices)'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='uno',
        choices=['deepcdr', 'deepttc', 'graphdrp', 'hidra', 'lgbm', 'tcnns', 'uno'],
        help='Model name (default: uno)'
    )
    parser.add_argument(
        '--metric',
        type=str,
        default='r2',
        choices=['r2', 'mae', 'rmse'],
        help='Performance metric (default: r2)'
    )
    parser.add_argument(
        '--outdir',
        type=str,
        default='./outputs',
        help='Output directory root (default: ./outputs)'
    )
    parser.add_argument(
        '--file_format',
        type=str,
        default='eps',
        choices=['png', 'eps', 'pdf', 'svg'],
        help='Figure file format (default: eps)'
    )
    args = parser.parse_args()

    # Create output directory structure
    outdir = Path(args.outdir) / 's6_overlap'
    outdir.mkdir(parents=True, exist_ok=True)
    fig_dir = outdir / 'figures'
    fig_dir.mkdir(parents=True, exist_ok=True)
    
    # Create logs directory before setting up logging
    logs_dir = Path('./logs')
    logs_dir.mkdir(parents=True, exist_ok=True)
    
    setup_logging(log_file=str(logs_dir / 's6_overlap.log'))
    
    # Setup paths
    preds_dir = Path(args.preds_dir)
    G_dir = Path(args.G_dir)
    
    # Get model name
    model_name = model_name_mapping[args.model]
    
    logging.info("=" * 50)
    logging.info("Step 6: Compute Drug and Cell Overlap Metrics")
    logging.info("=" * 50)
    logging.info(f"Model: {model_name} ({args.model})")
    logging.info(f"Metric: {args.metric}")
    logging.info(f"Input (predictions): {preds_dir}")
    logging.info(f"Input (G matrices): {G_dir}")
    logging.info(f"Output: {outdir}")
    
    # Validate input directories
    if not preds_dir.exists():
        logging.error(f"Predictions directory not found: {preds_dir}")
        logging.error("Please run Step 0 (s0_aggregate.py) or download predictions.")
        raise FileNotFoundError(f"Predictions directory not found: {preds_dir}")
    
    if not G_dir.exists():
        logging.error(f"G matrices directory not found: {G_dir}")
        logging.error("Please run Step 2 (s2_compute_G_matrices.py) first to generate G matrices.")
        raise FileNotFoundError(f"G matrices directory not found: {G_dir}")
    
    # Load G matrix
    g_csv = G_dir / f'{args.model}_{args.metric}_G_mean.csv'
    if not g_csv.exists():
        logging.error(f"G matrix not found: {g_csv}")
        logging.error(f"Please run Step 2 (s2_compute_G_matrices.py) first.")
        raise FileNotFoundError(f"G matrix not found: {g_csv}")
    
    logging.info(f"Found G matrix: {g_csv}")

    # === DRUGS ===
    drug_sets = build_entity_sets(preds_dir, REQUIRED_DRUG_COL, DATASET_ORDER, DEFAULT_REP_FILES, log_label="drug")
    drug_mats = compute_overlap_matrices(drug_sets, DATASET_ORDER)
    # drug_count = drug_mats["overlap_count"]
    # drug_jacc  = drug_mats["overlap_jaccard"]
    drug_covg  = drug_mats["directional_coverage"]
    # Save
    # drug_count.to_csv(outdir / "drug_overlap_count.csv")
    # drug_jacc.to_csv(outdir / "drug_overlap_jaccard.csv")
    drug_covg.to_csv(outdir / "drug_directional_coverage.csv")

    # === CELLS ===
    cell_sets = build_entity_sets(preds_dir, REQUIRED_CELL_COL, DATASET_ORDER, DEFAULT_REP_FILES, log_label="cell")
    cell_mats = compute_overlap_matrices(cell_sets, DATASET_ORDER)
    # cell_count = cell_mats["overlap_count"]
    # cell_jacc  = cell_mats["overlap_jaccard"]
    cell_covg  = cell_mats["directional_coverage"]
    # Save
    # cell_count.to_csv(outdir / "cell_overlap_count.csv")
    # cell_jacc.to_csv(outdir / "cell_overlap_jaccard.csv")
    cell_covg.to_csv(outdir / "cell_directional_coverage.csv")

    # === Load G and align ===
    G = load_performance_matrix(g_csv)

    # Align for plotting
    drug_covg_aligned, G_aligned = drug_covg.align(G, join='inner', axis=0)
    drug_covg_aligned, G_aligned = drug_covg_aligned.align(G_aligned, join='inner', axis=1)

    cell_covg_aligned, _ = cell_covg.align(G_aligned, join='inner', axis=0)
    cell_covg_aligned, _ = cell_covg_aligned.align(G_aligned, join='inner', axis=1)

    # Optional: counts/jaccard heatmaps (drug & cell)
    # (kept since they’re cheap and occasionally informative)
    # dcount_aligned, _ = drug_count.align(G_aligned, join='inner', axis=0)
    # dcount_aligned, _ = dcount_aligned.align(G_aligned, join='inner', axis=1)
    # djacc_aligned, _  = drug_jacc.align(G_aligned, join='inner', axis=0)
    # djacc_aligned, _  = djacc_aligned.align(G_aligned, join='inner', axis=1)

    # ccount_aligned, _ = cell_count.align(G_aligned, join='inner', axis=0)
    # ccount_aligned, _ = ccount_aligned.align(G_aligned, join='inner', axis=1)
    # cjacc_aligned, _  = cell_jacc.align(G_aligned, join='inner', axis=0)
    # cjacc_aligned, _  = cjacc_aligned.align(G_aligned, join='inner', axis=1)

    # === Heatmaps ===
    # Save in both specified format and PNG
    plot_heatmap(drug_covg_aligned,
                 title="Drug-set coverage (source-to-target)",
                 out_png=fig_dir / f"heatmap_directional_drug_coverage.{args.file_format}",
                 cmap='Oranges', vmin=0, vmax=1)
    plot_heatmap(drug_covg_aligned,
                 title="Drug-set coverage (source-to-target)",
                 out_png=fig_dir / f"heatmap_directional_drug_coverage.png",
                 cmap='Oranges', vmin=0, vmax=1)

    plot_heatmap(cell_covg_aligned,
                 title="Cell-line coverage (source-to-target)",
                 out_png=fig_dir / f"heatmap_directional_cell_coverage.{args.file_format}",
                 cmap='Purples', vmin=0, vmax=1)
    plot_heatmap(cell_covg_aligned,
                 title="Cell-line coverage (source-to-target)",
                 out_png=fig_dir / f"heatmap_directional_cell_coverage.png",
                 cmap='Purples', vmin=0, vmax=1)

    # === Scatter + Spearman (off-diagonals) ===
    # Drug
    x_d, y_d, labels_d = flatten_offdiag(drug_covg_aligned, G_aligned)
    # single-color - save in both formats
    plot_scatter(
        x_d, y_d, labels_d, ASSAY_MAP,
        title=f"Cross-dataset performance vs Drug-set coverage ({model_name})",
        out_png=fig_dir / f"scatter_drug_coverage_vs_G_all_{args.model}.{args.file_format}",
        xlabel="Drug-set coverage (source-to-target), |Ds ∩ Dt| / |Dt|",
        show_assay_split=False,
        color_all='tab:orange'
    )
    plot_scatter(
        x_d, y_d, labels_d, ASSAY_MAP,
        title=f"Cross-dataset performance vs Drug-set coverage ({model_name})",
        out_png=fig_dir / f"scatter_drug_coverage_vs_G_all_{args.model}.png",
        xlabel="Drug-set coverage (source-to-target), |Ds ∩ Dt| / |Dt|",
        show_assay_split=False,
        color_all='tab:orange'
    )
    # assay-split - save in both formats
    plot_scatter(
        x_d, y_d, labels_d, ASSAY_MAP,
        title=f"Cross-dataset performance vs Drug-set coverage (by assay) ({model_name})",
        out_png=fig_dir / f"scatter_drug_coverage_vs_G_by_assay_{args.model}.{args.file_format}",
        xlabel="Drug-set coverage (source-to-target), |Ds ∩ Dt| / |Dt|",
        show_assay_split=True,
        color_same='tab:orange',
        color_diff='0.55'   # medium gray
    )
    plot_scatter(
        x_d, y_d, labels_d, ASSAY_MAP,
        title=f"Cross-dataset performance vs Drug-set coverage (by assay) ({model_name})",
        out_png=fig_dir / f"scatter_drug_coverage_vs_G_by_assay_{args.model}.png",
        xlabel="Drug-set coverage (source-to-target), |Ds ∩ Dt| / |Dt|",
        show_assay_split=True,
        color_same='tab:orange',
        color_diff='0.55'   # medium gray
    )
    rho_d_all, p_d_all = spearmanr(x_d, y_d, nan_policy='omit')
    same_mask_d = np.array(filter_same_assay_pairs(labels_d, ASSAY_MAP))
    if np.any(same_mask_d):
        rho_d_same, p_d_same = spearmanr(x_d[same_mask_d], y_d[same_mask_d], nan_policy='omit')
    else:
        rho_d_same, p_d_same = np.nan, np.nan

    # Cell
    x_c, y_c, labels_c = flatten_offdiag(cell_covg_aligned, G_aligned)
    # single-color - save in both formats
    plot_scatter(
        x_c, y_c, labels_c, ASSAY_MAP,
        title=f"Cross-dataset performance vs Cell-line coverage ({model_name})",
        out_png=fig_dir / f"scatter_cell_coverage_vs_G_all_{args.model}.{args.file_format}",
        xlabel="Cell-line coverage (source-to-target), |Cs ∩ Ct| / |Ct|",
        show_assay_split=False,
        color_all='tab:purple'
    )
    plot_scatter(
        x_c, y_c, labels_c, ASSAY_MAP,
        title=f"Cross-dataset performance vs Cell-line coverage ({model_name})",
        out_png=fig_dir / f"scatter_cell_coverage_vs_G_all_{args.model}.png",
        xlabel="Cell-line coverage (source-to-target), |Cs ∩ Ct| / |Ct|",
        show_assay_split=False,
        color_all='tab:purple'
    )
    # assay-split - save in both formats
    plot_scatter(
        x_c, y_c, labels_c, ASSAY_MAP,
        title=f"Cross-dataset performance vs Cell-line coverage (by assay) ({model_name})",
        out_png=fig_dir / f"scatter_cell_coverage_vs_G_by_assay_{args.model}.{args.file_format}",
        xlabel="Cell-line coverage (source-to-target), |Cs ∩ Ct| / |Ct|",
        show_assay_split=True,
        color_same='tab:purple',
        color_diff='0.55'
    )
    plot_scatter(
        x_c, y_c, labels_c, ASSAY_MAP,
        title=f"Cross-dataset performance vs Cell-line coverage (by assay) ({model_name})",
        out_png=fig_dir / f"scatter_cell_coverage_vs_G_by_assay_{args.model}.png",
        xlabel="Cell-line coverage (source-to-target), |Cs ∩ Ct| / |Ct|",
        show_assay_split=True,
        color_same='tab:purple',
        color_diff='0.55'
    )
    rho_c_all, p_c_all = spearmanr(x_c, y_c, nan_policy='omit')
    same_mask_c = np.array(filter_same_assay_pairs(labels_c, ASSAY_MAP))
    if np.any(same_mask_c):
        rho_c_same, p_c_same = spearmanr(x_c[same_mask_c], y_c[same_mask_c], nan_policy='omit')
    else:
        rho_c_same, p_c_same = np.nan, np.nan

    # === Summary ===
    logging.info(f"\nResults:")
    logging.info(f"[DRUG] Off-diagonal Spearman ρ (all): {rho_d_all:.3f} (p={p_d_all:.3g})")
    if not np.isnan(rho_d_same):
        logging.info(f"[DRUG] Off-diagonal Spearman ρ (same-assay): {rho_d_same:.3f} (p={p_d_same:.3g})")
    logging.info(f"[CELL] Off-diagonal Spearman ρ (all):  {rho_c_all:.3f} (p={p_c_all:.3g})")
    if not np.isnan(rho_c_same):
        logging.info(f"[CELL] Off-diagonal Spearman ρ (same-assay): {rho_c_same:.3f} (p={p_c_same:.3g})")
    
    runtime = (time.time() - start_time) / 60
    logging.info(f"Runtime: {runtime:.2f} minutes")
    logging.info(f"Step 6 complete. Outputs saved to {outdir}")
    
    print(f'\n✅ Finished {Path(__file__).name}!')
    
    return True

if __name__ == "__main__":
    main()
