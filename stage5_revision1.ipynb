{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/ml_lab/projects/improve/data/experiments/cross-dataset-drp-paper\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap, Normalize\n",
    "\n",
    "import importlib\n",
    "import utils  # Import your module\n",
    "from utils import model_name_mapping, metrics_name_mapping\n",
    "\n",
    "# After making changes to utils.py, reload it\n",
    "importlib.reload(utils)\n",
    "\n",
    "# filepath = Path(__file__).parent\n",
    "filepath = Path(os.path.abspath(''))\n",
    "print(filepath)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# metrics_name_mapping = {\n",
    "#     \"r2\": \"R²\",\n",
    "#     \"mae\": \"MAE\",\n",
    "#     \"rmse\": \"RMSE\",\n",
    "#     \"stgr\": \"STGR\",\n",
    "#     \"stgi\": \"STGI\",\n",
    "# }\n",
    "\n",
    "# model_name_mapping = {\n",
    "#     \"deepcdr\": \"DeepCDR\",\n",
    "#     \"graphdrp\": \"GraphDRP\",\n",
    "#     \"hidra\": \"HiDRA\",\n",
    "#     \"lgbm\": \"LGBM\",\n",
    "#     \"tcnns\": \"tCNNS\",\n",
    "#     \"uno\": \"UNO\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>met</th>\n",
       "      <th>split</th>\n",
       "      <th>value</th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mse</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>deepcdr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mse</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>deepcdr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>deepcdr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   met  split     value   src   trg    model\n",
       "0  mse      0  0.006295  CCLE  CCLE  deepcdr\n",
       "1  mse      1  0.005950  CCLE  CCLE  deepcdr\n",
       "2  mse      2  0.005129  CCLE  CCLE  deepcdr"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = Path('splits_averaged')\n",
    "outdir = filepath / 'results_for_paper_revision'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# file_format = 'eps'\n",
    "# file_format = 'jpeg'\n",
    "file_format = 'png'\n",
    "# file_format = 'tiff'\n",
    "dpi = 600\n",
    "\n",
    "filename = 'all_models_scores.csv'\n",
    "canc_col_name = 'improve_sample_id'\n",
    "drug_col_name = 'improve_chem_id'\n",
    "\n",
    "# datasets_order = ['CCLE', 'CTRPv2', 'GDSCv1', 'GDSCv2', 'gCSI']  # alphabetical order\n",
    "datasets_order = ['gCSI', 'CCLE', 'GDSCv2', 'GDSCv1', 'CTRPv2']  # order by sample size\n",
    "show_plot = True\n",
    "\n",
    "all_scores = pd.read_csv(filepath / datadir / filename, sep=',')\n",
    "all_scores.iloc[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the metric\n",
    "metric_name = 'r2'\n",
    "\n",
    "# Specify the models you want to include\n",
    "models_to_include = []  # Replace with your desired models\n",
    "# models_to_include = [\"deepcdr\", \"deepttc\", \"graphdrp\", \"hidra\", \"lgbm\", \"uno\"]  # Replace with your desired models\n",
    "# models_to_include = [\"graphdrp\"]  # Replace with your desired models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests (Reviewer 3, comment 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model unique pairs: 21\n"
     ]
    }
   ],
   "source": [
    "comment_outdir = outdir / 'reviewer3_comment1'\n",
    "comment_outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "\n",
    "df = all_scores.copy()\n",
    "\n",
    "# Filtering for R² scores\n",
    "r2_df = df[df['met'] == 'r2'][['src', 'trg', 'model', 'split', 'value']]\n",
    "r2_df['model'] = r2_df['model'].map(model_name_mapping)\n",
    "\n",
    "# Defining models and datasets\n",
    "models = r2_df['model'].unique()\n",
    "src_datasets = r2_df['src'].unique()\n",
    "trg_datasets = r2_df['trg'].unique()\n",
    "\n",
    "model_pairwise_pairs = list(combinations(models, 2))\n",
    "print(f'Total model unique pairs: {len(model_pairwise_pairs)}')\n",
    "\n",
    "# Preparing results\n",
    "results = []\n",
    "skipped = []\n",
    "alpha = 0.05 / len(model_pairwise_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistical tests completed. Results saved to wilcoxon_tests_r2_all_combos.csv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>median_model1</th>\n",
       "      <th>median_model2</th>\n",
       "      <th>mean_r2_diff</th>\n",
       "      <th>p_value</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>DeepCDR</td>\n",
       "      <td>DeepTTC</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>0.791364</td>\n",
       "      <td>-0.023587</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>DeepCDR</td>\n",
       "      <td>GraphDRP</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>0.748778</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>DeepCDR</td>\n",
       "      <td>HiDRA</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>0.761346</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>DeepCDR</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>0.804346</td>\n",
       "      <td>-0.035490</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>DeepCDR</td>\n",
       "      <td>tCNNS</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>0.719130</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src   trg   model1    model2  median_model1  median_model2  mean_r2_diff  \\\n",
       "0  CCLE  CCLE  DeepCDR   DeepTTC       0.761925       0.791364     -0.023587   \n",
       "1  CCLE  CCLE  DeepCDR  GraphDRP       0.761925       0.748778      0.019620   \n",
       "2  CCLE  CCLE  DeepCDR     HiDRA       0.761925       0.761346      0.009445   \n",
       "3  CCLE  CCLE  DeepCDR      LGBM       0.761925       0.804346     -0.035490   \n",
       "4  CCLE  CCLE  DeepCDR     tCNNS       0.761925       0.719130      0.061112   \n",
       "\n",
       "    p_value  significant  \n",
       "0  0.019531        False  \n",
       "1  0.037109        False  \n",
       "2  0.492188        False  \n",
       "3  0.001953         True  \n",
       "4  0.013672        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_wilcoxon_tests_outpath = comment_outdir / 'all_wilcoxon_tests'\n",
    "all_wilcoxon_tests_outpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate over source-target pairs\n",
    "for src in src_datasets:\n",
    "    for trg in trg_datasets:\n",
    "        # Data for this pair\n",
    "        pair_df = r2_df[(r2_df['src'] == src) & (r2_df['trg'] == trg)]\n",
    "        if pair_df.empty:\n",
    "            continue\n",
    "\n",
    "        model_pairs = combinations(models, 2)\n",
    "\n",
    "        # Pairwise Wilcoxon tests\n",
    "        for model1, model2 in model_pairs:\n",
    "            scores1 = pair_df[pair_df['model'] == model1]['value'].values\n",
    "            scores2 = pair_df[pair_df['model'] == model2]['value'].values\n",
    "            \n",
    "            if len(scores1) == 10 and len(scores2) == 10:  # Ensure 10 splits\n",
    "                try:\n",
    "                    stat, p = wilcoxon(scores1, scores2, alternative='two-sided')\n",
    "                    mean_diff = np.mean(scores1 - scores2)\n",
    "                    results.append({\n",
    "                        'src': src,\n",
    "                        'trg': trg,\n",
    "                        'model1': model1,\n",
    "                        'model2': model2,\n",
    "                        'median_model1': np.median(scores1),\n",
    "                        'median_model2': np.median(scores2),\n",
    "                        'mean_r2_diff': mean_diff,\n",
    "                        'p_value': p,\n",
    "                        'significant': p < alpha\n",
    "                    })\n",
    "                except:\n",
    "                    print(f\"Wilcoxon test failed for {model1} vs {model2} on {src} → {trg}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping {model1} vs {model2} on {src} → {trg} due to insufficient splits: {len(scores1)} vs {len(scores2)}\")\n",
    "                skipped.append({\n",
    "                    'src': src,\n",
    "                    'trg': trg,\n",
    "                    'model1': model1,\n",
    "                    'model2': model2,\n",
    "                    'len_model1': len(scores1),\n",
    "                    'len_model2': len(scores2)\n",
    "                })\n",
    "\n",
    "# Saving significant results\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(comment_outdir / 'wilcoxon_tests_r2_all_combos.csv', index=False)\n",
    "print('Wilcoxon statistical tests completed. Results saved to wilcoxon_tests_r2_all_combos.csv.')\n",
    "\n",
    "display(res_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boxplots_outpath = comment_outdir / 'all_boxplots'\n",
    "all_boxplots_outpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generating boxplots\n",
    "for src in src_datasets:\n",
    "    for trg in trg_datasets:\n",
    "        pair_df = r2_df[(r2_df['src'] == src) & (r2_df['trg'] == trg)]\n",
    "        res_df_src_trg_combo = res_df[(res_df['src'] == src) & (res_df['trg'] == trg)]\n",
    "        res_df_src_trg_combo.to_csv(all_wilcoxon_tests_outpath / f'wilcoxon_tests_r2_{src}_{trg}_combos.csv', index=False)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(x='model', y='value', data=pair_df, hue='model', palette='Set3', legend=False,\n",
    "            showmeans=True, meanprops={'marker': 'o', 'markerfacecolor': 'black'})\n",
    "        plt.title(f'R² Scores: {src} → {trg}')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('R²')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(all_boxplots_outpath / f'boxplot_{src}_{trg}.{file_format}')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total selected rows: 36\n",
      "Selected source-target pairs: 12\n",
      "      src   trg    model1 model2  median_model1  median_model2  mean_r2_diff  \\\n",
      "0    CCLE  gCSI  GraphDRP    UNO      -0.383007       0.200078     -0.567031   \n",
      "1    CCLE  gCSI     tCNNS    UNO      -0.113735       0.200078     -0.506696   \n",
      "2    CCLE  gCSI      LGBM    UNO      -0.119092       0.200078     -0.308608   \n",
      "3  CTRPv2  CCLE     tCNNS    UNO       0.347740       0.627901     -0.306836   \n",
      "4  CTRPv2  CCLE  GraphDRP  tCNNS       0.597406       0.347740      0.273507   \n",
      "\n",
      "    p_value  \n",
      "0  0.001953  \n",
      "1  0.001953  \n",
      "2  0.001953  \n",
      "3  0.001953  \n",
      "4  0.001953  \n"
     ]
    }
   ],
   "source": [
    "# Save a selected subset of wilcoxon test results (used for S4 in the paper)\n",
    "\n",
    "# Filter 1: Significant results (p-value < alpha)\n",
    "# alpha = 0.05 / 21\n",
    "sig_df = res_df[res_df['significant'] == True]\n",
    "\n",
    "# Filter 2: At least one positive median R²\n",
    "th = 0.1  # Threshold for median R²\n",
    "pos_median_df = sig_df[(sig_df['median_model1'] > th) | (sig_df['median_model2'] > th)]\n",
    "\n",
    "# Filter 3: Exclude within-dataset pairs (source != target)\n",
    "cross_df = pos_median_df[pos_median_df['src'] != pos_median_df['trg']]\n",
    "\n",
    "# Filter 4 & 5: Select top 3 rows per source-target pair by absolute mean_r2_diff\n",
    "selected_rows = []\n",
    "src_trg_pairs = cross_df.groupby(['src', 'trg'])\n",
    "for (src, trg), group in src_trg_pairs:\n",
    "    # Sort by absolute mean_r2_diff (descending) and take top 3\n",
    "    top_rows = group.sort_values(by='mean_r2_diff', key=abs, ascending=False).head(3)\n",
    "    selected_rows.append(top_rows)\n",
    "\n",
    "# Combine selected rows\n",
    "selected_df = pd.concat(selected_rows, ignore_index=True)\n",
    "\n",
    "# Save selected results to CSV for S4\n",
    "selected_df.to_csv(comment_outdir / 'wilcoxon_tests_r2_selected.csv', index=False)\n",
    "\n",
    "# Print summary for verification\n",
    "print(f'Total selected rows: {len(selected_df)}')\n",
    "print(f\"Selected source-target pairs: {selected_df[['src', 'trg']].drop_duplicates().shape[0]}\")\n",
    "print(selected_df[['src', 'trg', 'model1', 'model2', 'median_model1', 'median_model2', 'mean_r2_diff', 'p_value']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source-target pairs with all negative mean R²: 8\n",
      "      src     trg\n",
      "0    CCLE  CTRPv2\n",
      "1    CCLE  GDSCv1\n",
      "2    CCLE  GDSCv2\n",
      "3  GDSCv1  CTRPv2\n",
      "4    gCSI    CCLE\n",
      "5    gCSI  CTRPv2\n",
      "6    gCSI  GDSCv1\n",
      "7    gCSI  GDSCv2\n",
      "Valid source-target pairs for boxplots: 12\n",
      "       src     trg\n",
      "0     CCLE    gCSI\n",
      "1   CTRPv2    CCLE\n",
      "2   CTRPv2  GDSCv1\n",
      "3   CTRPv2  GDSCv2\n",
      "4   CTRPv2    gCSI\n",
      "5   GDSCv1    CCLE\n",
      "6   GDSCv1  GDSCv2\n",
      "7   GDSCv1    gCSI\n",
      "8   GDSCv2    CCLE\n",
      "9   GDSCv2  CTRPv2\n",
      "10  GDSCv2  GDSCv1\n",
      "11  GDSCv2    gCSI\n"
     ]
    }
   ],
   "source": [
    "# Assume r2_df is available from your code (R² scores for all models, splits, src, trg)\n",
    "# r2_df = df[df['met'] == 'r2'][['src', 'trg', 'model', 'split', 'value']]\n",
    "# r2_df['model'] = r2_df['model'].map(model_name_mapping)\n",
    "\n",
    "# Compute mean R² per model for each source-target pair\n",
    "mean_r2_df = r2_df.groupby(['src', 'trg', 'model'])['value'].mean().reset_index(name='mean_r2')\n",
    "\n",
    "# Identify pairs where all models have mean R² lower than a threshold (e.g., 0.1)\n",
    "th = 0.1  # Threshold for mean R²\n",
    "negative_pairs = []\n",
    "src_trg_groups = mean_r2_df.groupby(['src', 'trg'])\n",
    "for (src, trg), group in src_trg_groups:\n",
    "    if (group['mean_r2'] < th).all():\n",
    "        negative_pairs.append((src, trg))\n",
    "\n",
    "# Save negative pairs to CSV for reference\n",
    "negative_pairs_df = pd.DataFrame(negative_pairs, columns=['src', 'trg'])\n",
    "negative_pairs_df.to_csv(comment_outdir / 'negative_r2_pairs.csv', index=False)\n",
    "\n",
    "# Print results\n",
    "print(f'Source-target pairs with all negative mean R²: {len(negative_pairs)}')\n",
    "print(negative_pairs_df)\n",
    "\n",
    "# Identify valid pairs for boxplots (exclude negative pairs and within-dataset pairs)\n",
    "valid_pairs = [(src, trg) for src, trg in r2_df[['src', 'trg']].drop_duplicates().values \n",
    "               if src != trg and (src, trg) not in negative_pairs]\n",
    "print(f'Valid source-target pairs for boxplots: {len(valid_pairs)}')\n",
    "print(pd.DataFrame(valid_pairs, columns=['src', 'trg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bubble Heatmap (Reviewer 2, comment 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is copied from stage4_generate_paper_plots.ipynb\n",
    "# -----------------------------------------------------------\n",
    "comment_outdir = outdir / 'reviewer2_comment8'\n",
    "comment_outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Extract all within-study results (src == trg)\n",
    "df = all_scores[\n",
    "    (all_scores[\"met\"] == metric_name) & \n",
    "    (all_scores[\"src\"] == all_scores[\"trg\"])  # src == trg\n",
    "].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "df = df.groupby([\"model\", \"src\"]).agg(mean_splits=(\"value\", \"mean\"), std_splits=(\"value\", \"std\")).reset_index()\n",
    "\n",
    "df_mean = df.sort_values(by=[\"src\", \"mean_splits\"], ascending=[True, False]).reset_index(drop=True)  # compute mean\n",
    "df_std = df.sort_values(by=[\"src\", \"std_splits\"], ascending=[True, False]).reset_index(drop=True)    # compute std\n",
    "# display(df.iloc[:7,:])\n",
    "\n",
    "# Mean across splits\n",
    "df_mean = df_mean.pivot(index=\"src\", columns=\"model\", values=\"mean_splits\")#.reset_index(drop=False)\n",
    "df_mean.index.name = None\n",
    "df_mean.columns.name = None\n",
    "df_mean = df_mean.T\n",
    "df_mean = df_mean.round(3)\n",
    "df_mean.index = df_mean.index.map(model_name_mapping)\n",
    "df_mean = df_mean[datasets_order]\n",
    "print('Mean across splits')\n",
    "display(df_mean)\n",
    "\n",
    "# Std across splits\n",
    "df_std = df_std.pivot(index=\"src\", columns=\"model\", values=\"std_splits\")#.reset_index(drop=False)\n",
    "df_std.index.name = None\n",
    "df_std.columns.name = None\n",
    "df_std = df_std.T\n",
    "df_std = df_std.round(3)\n",
    "df_std.index = df_std.index.map(model_name_mapping)\n",
    "df_std = df_std[datasets_order]\n",
    "print('Std across splits')\n",
    "display(df_std)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Add new row to df_mean containing the mean of each column\n",
    "datasets_mean = df_mean.mean(axis=0)\n",
    "df_mean.loc['Mean across datasets'] = datasets_mean\n",
    "\n",
    "# Add new column to df_mean containing the mean of each row\n",
    "models_mean = df_mean.mean(axis=1)\n",
    "df_mean['Mean across models'] = models_mean\n",
    "\n",
    "# Assign NA to cell of (mean_dataset, mean_model)\n",
    "df_mean.loc['Mean across datasets', 'Mean across models'] = np.nan\n",
    "df_mean.to_csv(comment_outdir / f'{metric_name}_mean_within_study_all_models.csv')\n",
    "\n",
    "print('Mean across splits (including across models and datasets)')\n",
    "display(df_mean)\n",
    "\n",
    "# Add new row to df_mean containing the mean of each column\n",
    "datasets_std = df_std.mean(axis=0)\n",
    "df_std.loc['Mean across datasets'] = datasets_std\n",
    "\n",
    "# Add new column to df_mean containing the mean of each row\n",
    "models_std = df_std.mean(axis=1)\n",
    "df_std['Mean across models'] = models_std\n",
    "\n",
    "# Assign NA to cell of (mean_dataset, mean_model)\n",
    "df_std.loc['Mean across datasets', 'Mean across models'] = np.nan\n",
    "df_std.to_csv(comment_outdir / f'{metric_name}_std_within_study_all_models.csv')\n",
    "\n",
    "print('Std across splits (including across models and datasets)')\n",
    "display(df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bubble Heatmap for Within-Dataset Results ---\n",
    "model_order = ['DeepCDR', 'DeepTTC', 'GraphDRP', 'HiDRA', 'LGBM', 'tCNNS', 'UNO']\n",
    "model_order = [s.lower() for s in model_order]  # Convert to lowercase to match the dataset\n",
    "\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "fontsize = 8\n",
    "bubble_size_min = 400\n",
    "bubble_size_max = 600\n",
    "# cmap = 'PiYG'\n",
    "# cmap = 'viridis'\n",
    "# cmap = 'plasma'\n",
    "# cmap = 'Reds'\n",
    "cmap = 'Oranges'\n",
    "\n",
    "# Extract within-study results (src == trg)\n",
    "df_within = all_scores[\n",
    "    (all_scores['met'] == metric_name) & \n",
    "    (all_scores['src'] == all_scores['trg'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Compute mean and std across splits\n",
    "df_within_agg = df_within.groupby(['model', 'src']).agg(\n",
    "    mean_splits=('value', 'mean'),\n",
    "    std_splits=('value', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Get min and max values for colorbar\n",
    "min_value = df_within_agg['mean_splits'].min()\n",
    "max_value = df_within_agg['mean_splits'].max()\n",
    "\n",
    "# Calculate inverse variance (1/std^2) for bubble size\n",
    "df_within_agg['inv_variance'] = 1 / (df_within_agg['std_splits'] ** 2)\n",
    "# Normalize inverse variance for bubble sizes (scale to [50, 500])\n",
    "inv_var_min, inv_var_max = df_within_agg['inv_variance'].min(), df_within_agg['inv_variance'].max()\n",
    "df_within_agg['bubble_size'] = bubble_size_min + bubble_size_max * (df_within_agg['inv_variance'] - inv_var_min) / (inv_var_max - inv_var_min)\n",
    "\n",
    "# Pivot for plotting\n",
    "df_mean_pivot = df_within_agg.pivot(index='model', columns='src', values='mean_splits')\n",
    "df_size_pivot = df_within_agg.pivot(index='model', columns='src', values='bubble_size')\n",
    "\n",
    "# Reorder indices and columns\n",
    "df_mean_pivot = df_mean_pivot.loc[model_order, datasets_order]\n",
    "df_size_pivot = df_size_pivot.loc[model_order, datasets_order]\n",
    "\n",
    "# Create bubble heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_style('whitegrid')\n",
    "x, y = np.meshgrid(range(len(datasets_order)), range(len(model_order)))\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "means = df_mean_pivot.values.flatten()\n",
    "sizes = df_size_pivot.values.flatten()\n",
    "\n",
    "# Plot scatter with dynamic colorbar range\n",
    "scatter = plt.scatter(x, y, s=sizes, c=means, cmap=cmap,\n",
    "    vmin=min_value, vmax=max_value,\n",
    "    edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Mean R²')\n",
    "\n",
    "# Add text annotations for mean R² values\n",
    "for i, dataset in enumerate(datasets_order):\n",
    "    for j, model in enumerate(model_order):\n",
    "        mean_r2 = df_mean_pivot.loc[model, dataset]\n",
    "        if not np.isnan(mean_r2):\n",
    "            # Choose text color based on bubble color (mean_r2)\n",
    "            text_color = 'white' if mean_r2 < 0 else 'black'  # White for negative (dark), black for positive (light)\n",
    "            plt.text(\n",
    "                i, j, f'{mean_r2:.2f}',\n",
    "                ha='center', va='center',\n",
    "                fontsize=fontsize, color=text_color,\n",
    "                weight='bold',  # Bold for better contrast\n",
    "                path_effects=[path_effects.withStroke(linewidth=0.5, foreground='white')]\n",
    "            )\n",
    "\n",
    "plt.xticks(range(len(datasets_order)), datasets_order, rotation=45, ha='right')\n",
    "plt.yticks(range(len(model_order)), [model_name_mapping.get(m.lower(), m) for m in model_order])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Model')\n",
    "plt.title('Within-Dataset R² Performance (Bubble Size: Inverse Variance)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(comment_outdir / f'bubble_heatmap_within_dataset.{file_format}', dpi=dpi, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "outpath = comment_outdir / f'bubble_heatmap_within_dataset.{file_format}'\n",
    "print(f'Bubble heatmap saved in: {outpath}')\n",
    "# print(f'Bubble heatmap saved in: {comment_outdir / \"bubble_heatmap_within_dataset.png\"}')\n",
    "print(f'Value range: min={min_value:.2f}, max={max_value:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract within-study results (src == trg)\n",
    "df_within = all_scores[\n",
    "    (all_scores['met'] == metric_name) & \n",
    "    (all_scores['src'] == all_scores['trg'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Compute mean and std across splits\n",
    "df_within_agg = df_within.groupby(['model', 'src']).agg(\n",
    "    mean_splits=('value', 'mean'),\n",
    "    std_splits=('value', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Reorder data for plotting\n",
    "df_within_agg['src'] = pd.Categorical(df_within_agg['src'], categories=datasets_order, ordered=True)\n",
    "df_within_agg['model'] = pd.Categorical(df_within_agg['model'], categories=model_order, ordered=True)\n",
    "\n",
    "# Create grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style('whitegrid')\n",
    "bar_plot = sns.barplot(\n",
    "    data=df_within_agg,\n",
    "    x='src',\n",
    "    y='mean_splits',\n",
    "    hue='model',\n",
    "    palette='tab10'\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "bar_width = 0.8 / len(model_order)  # Width per bar\n",
    "for i, dataset in enumerate(datasets_order):\n",
    "    for j, model in enumerate(model_order):\n",
    "        subset = df_within_agg[(df_within_agg['model'] == model) & (df_within_agg['src'] == dataset)]\n",
    "        if not subset.empty:\n",
    "            mean = subset['mean_splits'].iloc[0]\n",
    "            std = subset['std_splits'].iloc[0]\n",
    "            x_pos = i + (j - (len(model_order) - 1) / 2) * bar_width\n",
    "            plt.errorbar(x=x_pos, y=mean, yerr=std, fmt='none', capsize=3, color='black')\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Mean R²')\n",
    "plt.title('Within-Dataset R² Performance with Error Bars')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Set y-axis limits dynamically\n",
    "r2_min = (df_within_agg['mean_splits'] - df_within_agg['std_splits']).min()\n",
    "r2_max = (df_within_agg['mean_splits'] + df_within_agg['std_splits']).max()\n",
    "plt.ylim(min(0, r2_min - 0.05), max(1.0, r2_max + 0.05))\n",
    "\n",
    "plt.savefig(comment_outdir / f'bar_plot_within_r2.{file_format}', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "outpath = comment_outdir / f'bar_plot_within_r2.{file_format}'\n",
    "print(f'Bar plot saved in: {outpath}')\n",
    "# print(f'Bar plot saved in: {comment_outdir / \"bar_plot_within_r2.png\"}')\n",
    "print(f'R² range (with error bars): min={r2_min:.2f}, max={r2_max:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ovarian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
